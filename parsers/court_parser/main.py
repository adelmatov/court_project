"""
–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –ø–∞—Ä—Å–µ—Ä–∞
"""
import sys
import asyncio
import traceback
from typing import List, Optional

from core.parser import CourtParser
from config.settings import Settings
from search.document_handler import DocumentHandler
from utils.logger import setup_logger


async def parse_all_regions_from_config() -> dict:
    """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º –∏–∑ config.json"""
    logger = setup_logger('main', level='INFO')
    
    settings = Settings()
    ps = settings.parsing_settings
    
    year = ps.get('year', '2025')
    court_types = ps.get('court_types', ['smas'])
    start_from = ps.get('start_from', 1)
    max_number = ps.get('max_number', 9999)
    max_consecutive_empty = ps.get('max_consecutive_empty', 200)
    delay_between_requests = ps.get('delay_between_requests', 2)
    max_parallel_regions = ps.get('max_parallel_regions', 1)
    
    region_retry_max_attempts = ps.get('region_retry_max_attempts', 3)
    region_retry_delay = ps.get('region_retry_delay_seconds', 5)
    
    limit_regions = settings.get_limit_regions()
    limit_cases_per_region = settings.get_limit_cases_per_region()
    
    logger.info("=" * 70)
    logger.info(f"–ú–ê–°–°–û–í–´–ô –ü–ê–†–°–ò–ù–ì: {', '.join(court_types)} ({year})")
    logger.info("=" * 70)
    logger.info(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ config.json:")
    logger.info(f"  –ì–æ–¥: {year}")
    logger.info(f"  –¢–∏–ø—ã —Å—É–¥–æ–≤: {', '.join(court_types)}")
    logger.info(f"  –î–∏–∞–ø–∞–∑–æ–Ω –Ω–æ–º–µ—Ä–æ–≤: {start_from}-{max_number}")
    logger.info(f"  –õ–∏–º–∏—Ç –ø—É—Å—Ç—ã—Ö –ø–æ–¥—Ä—è–¥: {max_consecutive_empty}")
    logger.info(f"  –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏: {delay_between_requests} —Å–µ–∫")
    logger.info(f"  –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤: {max_parallel_regions}")
    logger.info(f"  Retry –Ω–∞ —Ä–µ–≥–∏–æ–Ω: {region_retry_max_attempts} –ø–æ–ø—ã—Ç–æ–∫")
    
    if limit_regions:
        logger.info(f"  üîí –õ–ò–ú–ò–¢ –†–ï–ì–ò–û–ù–û–í: {limit_regions}")
    if limit_cases_per_region:
        logger.info(f"  üîí –õ–ò–ú–ò–¢ –ó–ê–ü–†–û–°–û–í –ù–ê –†–ï–ì–ò–û–ù: {limit_cases_per_region}")
    
    logger.info("=" * 70)
    
    all_regions = settings.get_target_regions()
    
    if limit_regions:
        regions_to_process = all_regions[:limit_regions]
        logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {len(regions_to_process)} –∏–∑ {len(all_regions)} —Ä–µ–≥–∏–æ–Ω–æ–≤")
    else:
        regions_to_process = all_regions
        logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤—Å–µ {len(regions_to_process)} —Ä–µ–≥–∏–æ–Ω–æ–≤")
    
    total_stats = {
        'regions_processed': 0,
        'regions_failed': 0,
        'total_queries': 0,
        'total_cases_saved': 0
    }
    stats_lock = asyncio.Lock()
    
    semaphore = asyncio.Semaphore(max_parallel_regions)
    
    async with CourtParser() as parser:
        
        async def process_region_with_retry(region_key: str):
            async with semaphore:
                region_config = settings.get_region(region_key)
                
                for attempt in range(1, region_retry_max_attempts + 1):
                    try:
                        logger.info(f"\n{'='*70}")
                        if attempt > 1:
                            logger.info(f"üîÑ –†–µ–≥–∏–æ–Ω: {region_config['name']} (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{region_retry_max_attempts})")
                        else:
                            logger.info(f"–†–µ–≥–∏–æ–Ω: {region_config['name']}")
                        logger.info(f"{'='*70}")
                        
                        region_stats = await process_region_all_courts(
                            parser=parser,
                            settings=settings,
                            region_key=region_key,
                            court_types=court_types,
                            year=year,
                            start_from=start_from,
                            max_number=max_number,
                            max_consecutive_empty=max_consecutive_empty,
                            delay_between_requests=delay_between_requests,
                            limit_cases=limit_cases_per_region
                        )
                        
                        async with stats_lock:
                            total_stats['regions_processed'] += 1
                            total_stats['total_queries'] += region_stats['total_queries']
                            total_stats['total_cases_saved'] += region_stats['total_cases_saved']
                        
                        return region_stats
                    
                    except Exception as e:
                        if attempt < region_retry_max_attempts:
                            logger.warning(f"‚ö†Ô∏è –†–µ–≥–∏–æ–Ω {region_config['name']}: –æ—à–∏–±–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt})")
                            logger.warning(f"   {e}")
                            await parser.session_manager.create_session()
                            await asyncio.sleep(region_retry_delay)
                        else:
                            logger.error(f"‚ùå –†–µ–≥–∏–æ–Ω {region_config['name']} failed")
                            logger.error(traceback.format_exc())
                            async with stats_lock:
                                total_stats['regions_failed'] += 1
                            return None
        
        tasks = [process_region_with_retry(r) for r in regions_to_process]
        await asyncio.gather(*tasks, return_exceptions=True)
    
    logger.info("\n" + "=" * 70)
    logger.info("–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    logger.info(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–µ–≥–∏–æ–Ω–æ–≤: {total_stats['regions_processed']}")
    if total_stats['regions_failed'] > 0:
        logger.info(f"  –†–µ–≥–∏–æ–Ω–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏: {total_stats['regions_failed']}")
    logger.info(f"  –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {total_stats['total_queries']}")
    logger.info(f"  –í—Å–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {total_stats['total_cases_saved']}")
    logger.info("=" * 70)
    
    return total_stats


async def process_region_all_courts(
    parser,
    settings,
    region_key: str,
    court_types: List[str],
    year: str,
    start_from: int,
    max_number: int,
    max_consecutive_empty: int,
    delay_between_requests: float,
    limit_cases: Optional[int] = None
) -> dict:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Å—É–¥–æ–≤ —Ä–µ–≥–∏–æ–Ω–∞"""
    logger = setup_logger('main', level='INFO')
    region_config = settings.get_region(region_key)
    
    region_stats = {
        'region_key': region_key,
        'courts_processed': 0,
        'total_queries': 0,
        'total_cases_saved': 0,
        'courts_stats': {}
    }
    
    for court_key in court_types:
        court_config = region_config['courts'].get(court_key)
        if not court_config:
            logger.warning(f"‚ö†Ô∏è –°—É–¥ {court_key} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–≥–∏–æ–Ω–µ {region_key}")
            continue
            
        logger.info(f"\nüìç –°—É–¥: {court_config['name']}")
        
        try:
            court_stats = await parse_court(
                parser=parser,
                settings=settings,
                region_key=region_key,
                court_key=court_key,
                year=year,
                start_from=start_from,
                max_number=max_number,
                max_consecutive_empty=max_consecutive_empty,
                delay_between_requests=delay_between_requests,
                limit_cases=limit_cases
            )
            
            region_stats['courts_processed'] += 1
            region_stats['total_queries'] += court_stats['queries_made']
            region_stats['total_cases_saved'] += court_stats['cases_saved']
            region_stats['courts_stats'][court_key] = court_stats
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—É–¥–∞ {court_key}: {e}")
            logger.error(traceback.format_exc())
            continue
    
    logger.info(f"\n{'-'*70}")
    logger.info(f"–ò–¢–û–ì–ò –†–ï–ì–ò–û–ù–ê {region_config['name']}:")
    logger.info(f"  –°—É–¥–æ–≤: {region_stats['courts_processed']}/{len(court_types)}")
    logger.info(f"  –ó–∞–ø—Ä–æ—Å–æ–≤: {region_stats['total_queries']}")
    logger.info(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {region_stats['total_cases_saved']}")
    logger.info(f"{'-'*70}")
    
    return region_stats


async def parse_court(
    parser,
    settings,
    region_key: str,
    court_key: str,
    year: str,
    start_from: int,
    max_number: int,
    max_consecutive_empty: int,
    delay_between_requests: float,
    limit_cases: Optional[int] = None
) -> dict:
    """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ —Å—É–¥–∞"""
    logger = setup_logger('main', level='INFO')
    
    stats = {
        'missing_found': 0,
        'missing_filled': 0,
        'missing_not_found': 0,
        'new_queries': 0,
        'new_saved': 0,
        'consecutive_empty': 0
    }
    
    existing = await parser.db_manager.get_existing_case_numbers(
        region_key, court_key, year, settings
    )
    
    last_in_db = await parser.db_manager.get_last_sequence_number(
        region_key, court_key, year, settings
    )
    
    logger.info(f"üìä –ê–Ω–∞–ª–∏–∑ –ë–î:")
    logger.info(f"   –°—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –Ω–æ–º–µ—Ä–æ–≤: {len(existing)}")
    logger.info(f"   –ü–æ—Å–ª–µ–¥–Ω–∏–π –Ω–æ–º–µ—Ä: {last_in_db}")
    
    # –®–ê–ì 1: –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    if last_in_db > 0:
        full_range = set(range(start_from, last_in_db + 1))
        missing = sorted(full_range - existing)
        stats['missing_found'] = len(missing)
        
        if missing:
            logger.info(f"\n{'‚îÄ' * 70}")
            logger.info(f"–®–ê–ì 1: –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤")
            logger.info(f"{'‚îÄ' * 70}")
            logger.info(f"üìã –ü—Ä–æ–ø—É—â–µ–Ω–æ –Ω–æ–º–µ—Ä–æ–≤: {len(missing)}")
            
            for i, seq_num in enumerate(missing, 1):
                if limit_cases:
                    total_queries = stats['missing_filled'] + stats['missing_not_found'] + stats['new_queries']
                    if total_queries >= limit_cases:
                        logger.info(f"üîí –õ–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ ({limit_cases})")
                        break
                
                result = await parser.search_and_save(
                    region_key=region_key,
                    court_key=court_key,
                    sequence_number=seq_num,
                    year=year
                )
                
                if result['success'] and result.get('saved'):
                    stats['missing_filled'] += 1
                else:
                    stats['missing_not_found'] += 1
                
                if i % 10 == 0 or i == len(missing):
                    logger.info(
                        f"   [{i}/{len(missing)}] "
                        f"–ó–∞–ø–æ–ª–Ω–µ–Ω–æ: {stats['missing_filled']}, "
                        f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ: {stats['missing_not_found']}"
                    )
                
                await asyncio.sleep(delay_between_requests)
    
    # –®–ê–ì 2: –°–±–æ—Ä –Ω–æ–≤—ã—Ö –¥–µ–ª
    actual_start = last_in_db + 1 if last_in_db > 0 else start_from
    
    if actual_start <= max_number:
        logger.info(f"\n{'‚îÄ' * 70}")
        logger.info(f"–®–ê–ì 2: –°–±–æ—Ä –Ω–æ–≤—ã—Ö –¥–µ–ª")
        logger.info(f"{'‚îÄ' * 70}")
        logger.info(f"‚ñ∂Ô∏è  –°—Ç–∞—Ä—Ç —Å –Ω–æ–º–µ—Ä–∞: {actual_start}")
        
        current_number = actual_start
        
        while current_number <= max_number:
            if limit_cases:
                total_queries = (stats['missing_filled'] + stats['missing_not_found'] + 
                               stats['new_queries'])
                if total_queries >= limit_cases:
                    logger.info(f"üîí –õ–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ ({limit_cases})")
                    break
            
            if stats['consecutive_empty'] >= max_consecutive_empty:
                logger.info(f"üõë –õ–∏–º–∏—Ç –ø—É—Å—Ç—ã—Ö –ø–æ–¥—Ä—è–¥ ({max_consecutive_empty}), —Å—Ç–æ–ø")
                break
            
            result = await parser.search_and_save(
                region_key=region_key,
                court_key=court_key,
                sequence_number=current_number,
                year=year
            )
            
            stats['new_queries'] += 1
            
            if result['success'] and result.get('saved'):
                stats['new_saved'] += 1
                stats['consecutive_empty'] = 0
            elif result.get('error') == 'no_results':
                stats['consecutive_empty'] += 1
            elif result.get('error') == 'target_not_found' and court_key != 'smas':
                stats['consecutive_empty'] += 1
            
            if stats['new_queries'] % 10 == 0:
                logger.info(
                    f"   #{current_number} | "
                    f"–ó–∞–ø—Ä–æ—Å–æ–≤: {stats['new_queries']} | "
                    f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {stats['new_saved']} | "
                    f"–ü—É—Å—Ç—ã—Ö –ø–æ–¥—Ä—è–¥: {stats['consecutive_empty']}"
                )
            
            current_number += 1
            await asyncio.sleep(delay_between_requests)
    
    total_saved = stats['missing_filled'] + stats['new_saved']
    total_queries = (stats['missing_filled'] + stats['missing_not_found'] + 
                    stats['new_queries'])
    
    return {
        'queries_made': total_queries,
        'cases_saved': total_saved,
        'consecutive_empty': stats['consecutive_empty'],
        'missing_filled': stats['missing_filled'],
        'new_saved': stats['new_saved']
    }


async def update_cases_history():
    """
    –†–µ–∂–∏–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: —Å–æ–±—ã—Ç–∏—è + –¥–æ–∫—É–º–µ–Ω—Ç—ã
    """
    logger = setup_logger('main', level='INFO')
    
    settings = Settings()
    update_config = settings.config.get('update_settings', {})
    docs_config = settings.config.get('documents_settings', {})
    
    if not update_config.get('enabled', True):
        logger.warning("‚ö†Ô∏è Update Mode –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")
        return
    
    interval_days = update_config.get('update_interval_days', 2)
    filters = update_config.get('filters', {})
    
    storage_dir = docs_config.get('storage_dir', './documents')
    download_delay = docs_config.get('download_delay', 2.0)
    
    logger.info("\n" + "=" * 70)
    logger.info("–†–ï–ñ–ò–ú –û–ë–ù–û–í–õ–ï–ù–ò–Ø: –°–û–ë–´–¢–ò–Ø + –î–û–ö–£–ú–ï–ù–¢–´")
    logger.info("=" * 70)
    logger.info(f"–ò–Ω—Ç–µ—Ä–≤–∞–ª: {interval_days} –¥–Ω–µ–π")
    if filters.get('defendant_keywords'):
        logger.info(f"–§–∏–ª—å—Ç—Ä –ø–æ –æ—Ç–≤–µ—Ç—á–∏–∫—É: {filters['defendant_keywords']}")
    if filters.get('exclude_event_types'):
        logger.info(f"–ò—Å–∫–ª—é—á–∏—Ç—å —Å–æ–±—ã—Ç–∏—è: {filters['exclude_event_types']}")
    logger.info("=" * 70)
    
    stats = {
        'cases_updated': 0,
        'events_added': 0,
        'documents_downloaded': 0,
        'errors': 0,
        'skipped': 0
    }
    
    async with CourtParser() as parser:
        doc_handler = DocumentHandler(
            base_url=settings.base_url,
            storage_dir=storage_dir,
            regions_config=settings.regions
        )
        
        # –≠—Ç–∞–ø 1: –î–µ–ª–∞ –°–ú–ê–° –±–µ–∑ —Å—É–¥—å–∏
        logger.info("\nüìã –≠—Ç–∞–ø 1: –î–µ–ª–∞ –°–ú–ê–° –±–µ–∑ —Å—É–¥—å–∏...")
        smas_cases = await parser.db_manager.get_smas_cases_without_judge(settings, interval_days)
        logger.info(f"   –ù–∞–π–¥–µ–Ω–æ: {len(smas_cases)}")
        
        for case_number in smas_cases:
            result = await _process_single_case(
                parser, doc_handler, case_number, download_delay, logger
            )
            _update_stats(stats, result)
        
        # –≠—Ç–∞–ø 2: –î–µ–ª–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        logger.info(f"\nüìã –≠—Ç–∞–ø 2: –î–µ–ª–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º...")
        keyword_cases = await parser.db_manager.get_cases_for_update({
            'defendant_keywords': filters.get('defendant_keywords', []),
            'exclude_event_types': filters.get('exclude_event_types', []),
            'update_interval_days': interval_days
        })
        logger.info(f"   –ù–∞–π–¥–µ–Ω–æ: {len(keyword_cases)}")
        
        for case_number in keyword_cases:
            result = await _process_single_case(
                parser, doc_handler, case_number, download_delay, logger
            )
            _update_stats(stats, result)
    
    # –ò—Ç–æ–≥–∏
    logger.info("\n" + "=" * 70)
    logger.info("–ò–¢–û–ì–ò –û–ë–ù–û–í–õ–ï–ù–ò–Ø:")
    logger.info(f"  –û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–µ–ª: {stats['cases_updated']}")
    logger.info(f"  –î–æ–±–∞–≤–ª–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π: {stats['events_added']}")
    logger.info(f"  –°–∫–∞—á–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats['documents_downloaded']}")
    logger.info(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}")
    logger.info(f"  –û—à–∏–±–æ–∫: {stats['errors']}")
    logger.info("=" * 70)


async def _process_single_case(parser, doc_handler, case_number: str, delay: float, logger) -> dict:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –¥–µ–ª–∞: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π + –¥–æ–∫—É–º–µ–Ω—Ç—ã"""
    result = {'updated': False, 'events_added': 0, 'documents': 0, 'error': False}
    
    try:
        logger.info(f"   üîÑ {case_number}")
        
        # 1. –ü–æ–∏—Å–∫ –Ω–∞ —Å–∞–π—Ç–µ
        results_html, cases = await parser.search_case_by_number(case_number)
        
        if not results_html or not cases:
            logger.warning(f"      ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ —Å–∞–π—Ç–µ")
            result['skipped'] = True
            return result
        
        # 2. –ù–∞–π—Ç–∏ —Ü–µ–ª–µ–≤–æ–µ –¥–µ–ª–æ
        target_case = next((c for c in cases if c.case_number == case_number), None)
        
        if not target_case or target_case.result_index is None:
            logger.warning(f"      ‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω")
            result['skipped'] = True
            return result
        
        # 3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π –≤ –ë–î
        save_result = await parser.db_manager.update_case(target_case)
        
        if save_result.get('events_added', 0) > 0:
            result['events_added'] = save_result['events_added']
            result['updated'] = True
            logger.info(f"      ‚úÖ +{result['events_added']} —Å–æ–±—ã—Ç–∏–π")
        
        # 4. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        case_id = save_result.get('case_id') or await parser.db_manager.get_case_id(case_number)
        
        if case_id:
            session = await parser.session_manager.get_session()
            existing_keys = await parser.db_manager.get_document_keys(case_id)
            
            downloaded = await doc_handler.fetch_all_documents(
                session=session,
                results_html=results_html,
                case_number=case_number,
                case_index=target_case.result_index,
                existing_keys=existing_keys,
                delay=delay
            )
            
            if downloaded:
                await parser.db_manager.save_documents(case_id, downloaded)
                result['documents'] = len(downloaded)
                result['updated'] = True
                logger.info(f"      üìé +{len(downloaded)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            
            await parser.db_manager.mark_documents_downloaded(case_id)
        
        await asyncio.sleep(delay)
        
    except Exception as e:
        logger.error(f"      ‚ùå {case_number}: {e}")
        result['error'] = True
    
    return result


def _update_stats(stats: dict, result: dict):
    """–û–±–Ω–æ–≤–∏—Ç—å –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
    if result.get('error'):
        stats['errors'] += 1
    elif result.get('skipped'):
        stats['skipped'] += 1
    elif result.get('updated'):
        stats['cases_updated'] += 1
        stats['events_added'] += result.get('events_added', 0)
        stats['documents_downloaded'] += result.get('documents', 0)
    else:
        stats['skipped'] += 1


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger = setup_logger('main', level='INFO')
    
    logger.info("\n" + "=" * 70)
    logger.info("–ü–ê–†–°–ï–† –°–£–î–ï–ë–ù–´–• –î–ï–õ –ö–ê–ó–ê–•–°–¢–ê–ù–ê v2.1")
    logger.info("=" * 70)
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    mode = 'parse'
    
    if '--mode' in sys.argv:
        idx = sys.argv.index('--mode')
        if idx + 1 < len(sys.argv):
            mode = sys.argv[idx + 1]
    
    try:
        if mode == 'parse':
            asyncio.run(parse_all_regions_from_config())
        
        elif mode == 'update':
            asyncio.run(update_cases_history())
        
        else:
            logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º: {mode}")
            logger.info("–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–∂–∏–º—ã:")
            logger.info("  --mode parse   (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
            logger.info("  --mode update  (—Å–æ–±—ã—Ç–∏—è + –¥–æ–∫—É–º–µ–Ω—Ç—ã)")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(0)
    except Exception as e:
        logger.critical(f"\nüí• –û—à–∏–±–∫–∞: {e}")
        logger.debug(traceback.format_exc())
        sys.exit(1)


if __name__ == '__main__':
    main()